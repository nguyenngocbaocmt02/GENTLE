{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13776 16177\n",
      "13745 19 12\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "from datasets import data_preparation\n",
    "import wgan\n",
    "from airt.keras.layers import MonoDense\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from models.torch_mlp import MLPM\n",
    "\n",
    "file_paths = [\"cps.csv\"]\n",
    "\n",
    "# Read data from each CSV file and concatenate them\n",
    "raw_data_list = [pd.read_csv(file_path) for file_path in file_paths]\n",
    "raw_data = pd.concat(raw_data_list, axis=0, ignore_index=True)\n",
    "x, y, _ = data_preparation(raw_data, name=\"cps\", balance=0)\n",
    "x = x.numpy()\n",
    "y = y.numpy()\n",
    "grouped_by_x = {}\n",
    "index_for = {}\n",
    "for i in range(len(x)):\n",
    "    current_x = tuple(x[i])\n",
    "    if current_x not in grouped_by_x:\n",
    "        grouped_by_x[current_x] = []\n",
    "        index_for[current_x] = []\n",
    "    grouped_by_x[current_x].append(y[i])\n",
    "    index_for[current_x].append(i)\n",
    "\n",
    "highest_freq_x = None\n",
    "max_num = 0\n",
    "print(len(grouped_by_x), len(x))\n",
    "list_check = []\n",
    "train_index = []\n",
    "val_index = []\n",
    "test_index = []\n",
    "train_covariate_cnt = 0\n",
    "val_covariate_cnt = 0\n",
    "test_covariate_cnt = 0\n",
    "for current_x, y_values in grouped_by_x.items():\n",
    "    num_samples = len(y_values)\n",
    "    if num_samples > 30:\n",
    "        list_check.append(current_x)\n",
    "        test_index += index_for[current_x]\n",
    "        test_covariate_cnt += 1\n",
    "    elif num_samples > 20 and num_samples <= 30:\n",
    "        list_check.append(current_x)\n",
    "        val_index += index_for[current_x]\n",
    "        val_covariate_cnt += 1\n",
    "    else:\n",
    "        train_index += index_for[current_x]\n",
    "        train_covariate_cnt += 1\n",
    "\n",
    "    if highest_freq_x is None:\n",
    "        highest_freq_x = current_x\n",
    "        max_num = num_samples\n",
    "    if num_samples > max_num:\n",
    "        highest_freq_x = current_x\n",
    "        max_num = num_samples\n",
    "\n",
    "print(train_covariate_cnt, val_covariate_cnt, test_covariate_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.iloc[train_index].to_csv(\"train.csv\", index=False)\n",
    "raw_data.iloc[val_index].to_csv(\"val.csv\", index=False)\n",
    "raw_data.iloc[test_index].to_csv(\"test.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fgd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
